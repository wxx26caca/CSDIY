# 容器高手实战课

## 理解进程

Linux 启动过程

> 打开电源 -> BIOS/boot loader -> 加载内核 -> 完成系统初始化 -> 启动 1 号用户进程（init进程）-> ...

`kill <pid>`, 直接向一个进程发送一个信号, 缺省情况下不指定信号的类型, 那么这个信号就是 *SIGTERM*. 也可以指定信号类型, 比如命令 "kill -9 pid", 这里的 9, 就是编号为 9 的信号, *SIGKILL* 信号.

`kill -l` 可以列出所有的信号编号从 1-31. 常见的场景:

- 按下 Ctrl+C, 当前运行的进程就会收到一个信号 *SIGINT* (2) 而退出;
  
- 内存访问出错了，当前的进程就会收到另一个信号 *SIGSEGV* (11);
  
- `kill <pid>`, 缺省情况下进程会收到 *SIGTERM* (15) 信号;

- `kill -9 <pid>`, *SIGKILL* (9)

对于每一个信号, 进程对它的处理都有下面三个选择:

- 第一个选择是**忽略（Ignore）**, 就是对这个信号不做任何处理, *SIGKILL* 和 *SIGSTOP* 除外;

- 第二个选择是**捕获（Catch）**, 就是指让用户进程可以注册自己针对这个信号的 handler, *SIGKILL* 和 *SIGSTOP* 除外;

- 第三个选择是**缺省行为（Default）**, Linux 为每个信号都定义了一个缺省的行为, `man 7 signal` 来查看每个信号的缺省行为.

> 特权信号就是 Linux 为 kernel 和超级用户去删除任意进程所保留的, 不能被忽略也不能被捕获. 那么进程一旦收到 *SIGKILL*, 就要退出.

Linux 的实现里, `kill` 命令会调用 `kill()` 系统调用从而进入内核函数 `sys_kill()`, `sys_kill()` 会调用 `_send_signal()` 函数, 然后会用 `sig_task_ignored()` 来做判断. `sig_task_ignored()` 函数会决定内核在什么情况下会忽略信号.

```c
// file : kernel/signal.c

static bool sig_task_ignored(struct task_struct *t, int sig, bool force)
{
        void __user *handler;
        handler = sig_handler(t, sig);

        /* SIGKILL and SIGSTOP may not be sent to the global init */
        if (unlikely(is_global_init(t) && sig_kernel_only(sig)))

                return true;

        if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
            handler == SIG_DFL && !(force && sig_kernel_only(sig)))
                return true;

        /* Only allow kernel generated signals to this kthread */
        if (unlikely((t->flags & PF_KTHREAD) &&
                     (handler == SIG_KTHREAD_KERNEL) && !force))
                return true;

        return sig_handler_ignored(handler, sig);

}
```

重点看一些第二个判断:
- `!(force && sig_kernel_only(sig))`, force 值对于同一个 Namespace 里发出的信号来说, 调用值是 0.

- `handler == SIG_DFL`, 对于每个信号, 用户进程如果不注册一个自己的 handler, 就会有一个系统缺省的 handler, 这个缺省的 handler 就叫作 *SIG_DFL*. 特权信号 *SIG_KILL* 不允许被捕获，所以它的 handler 也是 *SIG_DFL*.

- `unlikely(t->signal->flags & SIGNAL_UNKILLABLE)`, 参考下面的代码, 可以看出对于 init 进程来说, 被创建的时候就会打上 *SIGNAL_UNKILLABLE* 的 flags.

```c
// file : kernel/fork.c
                       if (is_child_reaper(pid)) {
                                ns_of_pid(pid)->child_reaper = p;
                                p->signal->flags |= SIGNAL_UNKILLABLE;
                        }

/*

 * is_child_reaper returns true if the pid is the init process
 * of the current namespace. As this one could be checked before
 * pid_ns->child_reaper is assigned in copy_process, we check
 * with the pid number.
 */

static inline bool is_child_reaper(struct pid *pid)
{
        return pid->numbers[pid->level].nr == 1;
}
```

综上分析可以看出, 最重要的就是 **handler == SIG_DFL**. 如果自己注册了信号的 handler, 那么这个信号的 handler 就不再是 *SIG_DFL*, 所以即使是 init 进程在接收到 *SIGTERM* 之后也是可以退出的.

> 由于 *SIGKILL* 是一个特例, 因为 *SIGKILL* 是不允许被注册用户 handler 的 (还有一个不允许注册用户 handler 的信号是 *SIGSTOP*), 那么它只有 *SIG_DFL* handler. 所以 init 进程是永远不能被 *SIGKILL* 所杀, 但是可以被 *SIGTERM* 杀死.

> `man proc` `/proc/[pid]/status` `man 7 signal` 中的 **SigBlk, SigIgn, SigCgt**: Masks (expressed in hexadecimal) indicating signals being  blocked,  ignored, and caught (see signal(7)).

总结：

- `kill -9 1` 在容器中是不工作的, 内核阻止了 1 号进程对 *SIGKILL* 特权信号的响应.

- `kill 1` 分两种情况, 如果 1 号进程没有注册 *SIGTERM* 的 handler, 那么对 *SIGTERM* 信号也不响应, 如果注册了 handler, 那么就可以响应 *SIGTERM* 信号.

## 僵尸进程

> Processes marked `<defunct>` are dead processes (so-called "zombies") that remain because their parent has not destroyed them properly. These processes will be destroyed by init(8) if the parent process exits. from `man ps`

| state | meaning |
| :---: | :----------------------------------------------------------------- |
| D     | uninterruptible sleep (usually IO) |
| I     | Idle kernel thread |
| R     | running or runnable (on run queue) |
| S     | interruptible sleep (waiting for an event to complete) |
| T     | stopped by job control signal |
| t     | stopped by debugger during the tracing |
| W     | paging (not valid since the 2.6.xx kernel) |
| X     | dead (should never be seen) |
| Z     | defunct ("zombie") process, terminated but not reaped by its parent |

进程在调用 `do_exit()` 退出的时候, 还有两个状态. 一个是 `EXIT_DEAD`, 也就是进程在真正结束退出的那一瞬间的状态; 第二个是 `EXIT_ZOMBIE` 状态, 这是进程在 `EXIT_DEAD` 前的一个状态, 僵尸进程就是处于这个状态中.

Linux 进程总数目可以通过查看 `cat /proc/sys/kernel/pid_max` 得到. 对于 cpu 个数小于等于 32 的系统, 对应的值为 32*1024=32768; 大于 32 的系统，对应的值为 cpu_number * 1024.

对于容器来说, 可以借助 `pid Cgroup` 来限制其最大进程数, 它的 Cgroup 文件系统挂载点在 `/sys/fs/cgroup/pids`.

在一个容器建立之后, 创建容器的服务会在 `/sys/fs/cgroup/pids` 下建立一个子目录, 就是一个控制组. 控制组里最关键的一个文件就是 **pids.max**. 这个文件中的数值就是这个容器中允许的最大进程数目.

从内核进程的 `do_exit()` (kernel/exit.c) 函数中可以看到, 僵尸进程 task_struct 里的 mm/shm/sem/files 等文件资源都已经释放了, 只留下了一个 stask_struct instance 空壳, 并且, 这个进程也已经不响应任何的信号了.

**进程数目在每个容器中也是有限的**, 是一种很宝贵的资源.

```c
/* 模拟产生僵尸进程的程序 */
# include <stdio.h>
# include <stdlib.h>
# include <sys/types.h>
# include <sys/wait.h>
# include <unistd.h>
int main(int argc, char *argv[])
{
       int i;
       int total;

       if (argc < 2) {
              total = 1;
       } else {
              total = atoi(argv[1]);
       }

       printf("To create %d processes\n", total);

       for (i = 0; i < total; i++) {
              pid_t pid = fork();
 
              if (pid == 0) {
                      printf("Child => PPID: %d PID: %d\n", getppid(),
                             getpid());
                      sleep(60);
                      printf("Child process exits\n");
                      exit(EXIT_SUCCESS);
              } else if (pid > 0) {
                      printf("Parent created child %d\n", i);
              } else {
                      printf("Unable to create child process. %d\n", i);
                      break;
              }
       }

       printf("Parent is sleeping\n");

       /* 添加清理僵尸进程的方法 */
       for (i = 0; i < total; i++) {
            int status;
            wait(&status);
       }

       while (1) {
              sleep(100);
       }

       return EXIT_SUCCESS;
}
```

**父进程在创建完子进程之后就不管了**, 这就是造成子进程变成僵尸进程的原因.

解决方式: 在 Linux 中的进程退出之后, 如果进入僵尸状态, 我们就需要**父进程调用 wait() 系统调用**, 去回收僵尸进程的最后的那些系统资源, 比如进程号资源.

- `wait()` 系统调用是一个阻塞的调用，如果没有子进程是僵尸进程的话，这个调用就一直不会返回，那么整个进程就会被阻塞住，而不能去做别的事了。

- `waitpid()` 系统调用有一个参数 `WNOHANG`，它的含义就是，如果在调用的时候没有僵尸进程，那么函数就马上返回了。

总结：

- 每一个 Linux 进程在退出的时候都会进入一个僵尸状态（EXIT_ZOMBIE）；

- 僵尸进程如果不清理，就会消耗系统中的进程数资源，最坏的情况是导致新的进程无法启动；

- 僵尸进程一定需要父进程调用 `wait()` 或者 `waitpid()` 系统调用来清理，这也是容器中 init 进程必须具备的一个功能。

## 进程退出

在 init 进程退出之后，容器内的其他进程也都立刻退出了。不过不同的是，init 进程收到的是 *SIGTERM* 信号，而其他进程收到的是 *SIGKILL* 信号。

Linux 信号背后的两个重要的系统调用是 `kill()` 和 `signal()`。`man 2 kill` 和 `man 2 signal` 可以查看函数定义。进程对信号的处理其实就包括两个问题，一个是**进程如何发送信号**，另一个是**进程收到信号后如何处理**。

```c
// kill system call

NAME
       kill - send signal to a process

SYNOPSIS
       #include <sys/types.h>
       #include <signal.h>

       int kill(pid_t pid, int sig);

RETURN VALUE
       On  success  (at least one signal was sent), zero is returned.  On error, -1 is returned, and errno is set ap‐
       propriately.

// signal system call

NAME
       signal - ANSI C signal handling

SYNOPSIS
       #include <signal.h>

       typedef void (*sighandler_t)(int);

       sighandler_t signal(int signum, sighandler_t handler);

RETURN VALUE
       signal() returns the previous value of the signal handler, or SIG_ERR on error.  In the event of an error, er‐
       rno is set to indicate the cause.
```

`signal()` 系统调用的三种行为：

- 捕获，调用自己注册的 handler。

- 忽略，特殊的 handler `SIG_IGN`。

- 缺省，默认执行内核中对各种信号的缺省代码。常见的缺省行为有：退出（terminate），暂停（stop），忽略（ignore）

> *SIGKIL* 和 *SIGSTOP* 是两个特权信号，它们不能被捕获和忽略，否则会返回 *SIG_ERR*。

问题 1：为什么在停止一个容器的时候，容器 init 进程收到的 *SIGTERM* 信号，而容器中其他进程却会收到 *SIGKILL* 信号呢？

回答：当 Linux 进程收到 *SIGTERM* 信号并且使进程退出，这时 Linux 内核对处理进程退出的入口点就是 do_exit() 函数，do_exit() 函数中会释放进程的相关资源，比如内存，文件句柄，信号量等等。在做完这些工作之后，它会调用一个 exit_notify() 函数，用来通知和这个进程相关的父子进程等。对于容器来说，还要考虑 Pid Namespace 里的其他进程。这里调用的就是 zap_pid_ns_processes() 这个函数，而在这个函数中，如果是处于退出状态的 init 进程，它会向 Namespace 中的其他进程都发送一个 *SIGKILL* 信号。

问题 2：在容器被停止的时候，该怎么做，才能让容器中的进程收到 *SIGTERM* 信号呢？

回答：让容器 init 进程来转发 *SIGTERM* 信号。在容器的 init 进程中对收到的信号做个转发，发送到容器中的其他子进程，这样容器中的所有进程在停止时，都会收到 *SIGTERM*，而不是 *SIGKILL* 信号了。

## 限制 CPU

Linux `top` 命令中 CPU state 详解，CPU state percentages based on the interval since the last refresh。

| CPU state   | meaning                                    |
| :--------   | :--------                                  |
| us, user    | time running un-niced user processes       |
| sy, system  | time running kernel processes              |
| ni, nice    | time running niced user processes          |
| id, idle    | time spent in the kernel idle handler      |
| wa, IO-wait | time waiting for I/O completion            |
| hi          | time spent servicing hardware interrupts   |
| si          | time spent servicing software interrupts   |
| st          | time stolen from this vm by the hypervisor |

> wa, hi, si 所消耗的时间都不计入进程 CPU 时间。

每个 Cgroups 子系统都是通过一个虚拟文件系统挂载点的方式，挂到一个缺省的目录下，CPU Cgroup 一般在 Linux 发行版里会放在 /sys/fs/cgroup/cpu 这个目录下。`man cgroups`。

整个控制组（Control Group）在 /sys/fs/cgroup/cpu 目录下呈现的是一个树状的层级关系（hierarchy）。

[树状控制组层级关系示意图](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/assets/8b86bc86706b0bbfe8fe157ee21b6454.jpeg)

Linux 中用 CFS（Completely Fair Scheduler，完全公平调度器）对普通的进程进行调度，它实现的策略有三种（参考 [CFS](https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt)）：

- SCHED_NORMAL (traditionally called SCHED_OTHER): The scheduling policy that is used for regular tasks.

- SCHED_BATCH: Does not preempt nearly as often as regular tasks would, thereby allowing tasks to run longer and make better use of caches but at the cost of interactivity. This is well suited for batch jobs.

- SCHED_IDLE: This is even weaker than nice 19, but its not a true idle timer scheduler in order to avoid to get into priority inversion problems which would deadlock the machine.

CPU cgroup 中与 CFS 相关的参数有三个：`cpu.cfs_period_us`, `cpu.cfs_quota_us`, `cpu.shares`

- `cpu.cfs_quota_us` 和 `cpu.cfs_period_us` 这两个值决定了每个控制组中所有进程的可使用 CPU 资源的最大值。
    
  - `cpu.cfs_period_us` 是 CFS 算法的一个调度周期，一般它的值是 100000，以 microseconds 为单位。
  
  - `cpu.cfs_quota_us` 是 CFS 算法中在一个调度周期里这个控制组被允许的运行时间

  - 如果 quota/period > 1，则表示需要多于 1 个 CPU 来执行

- `cpu.shares` 这个值决定了 CPU Cgroup 子系统下控制组可用 CPU 的相对比例，不过只有当系统上 CPU 完全被占满的时候，这个比例才会在各个控制组间起作用。

  - `cpu.shares` 是 CPU Cgroup 对于控制组之间的 CPU 分配比例，它的缺省值是 1024。

```shell
test@E-5CG2300SB4:/sys/fs/cgroup/cpu$ cat cpu.cfs_period_us
100000  # 100毫秒
test@E-5CG2300SB4:/sys/fs/cgroup/cpu$ cat cpu.cfs_quota_us
-1
test@E-5CG2300SB4:/sys/fs/cgroup/cpu$ cat cpu.shares
1024   # 1024 表示 1 个 CPU 的比例
```

总结：
Kubernetes 中 Limit CPU 就是容器所在 Cgroup 控制组中的 CPU 上限值，Request CPU 的值就是控制组中的 `cpu.shares` 的值。

## CPU 开销

`top` 命令中 cpu 使用率的计算 `进程的 CPU 使用率 =((utime_2 – utime_1) + (stime_2 – stime_1)) * 100.0 / (HZ * et * 1 )`

- utime，从 `/proc/[pid]/stat` 文件中拿到的值。表示进程的用户态部分在 Linux 调度中获得 CPU 的 ticks。（`man proc`)

- stime，从 `/proc/[pid]/stat` 文件中拿到的值。表示进程的内核态部分在 Linux 调度中获得 CPU 的 ticks。

- HZ，1 秒钟里 ticks 的次数

- et，瞬时时间，即 utime_1 和 utime_2 这两个值的时间间隔

- 1，1 个 CPU

utime 和 stime 都是一个累计值，也就是说从进程启动开始，这两个值就是一直在累积增长的。单个进程 CPU 总的开销就是用户态加上内核态，也就是在 1 秒瞬时进程总的 CPU ticks 等于 (utime_2 – utime_1) + (stime_2 – stime_1)。

- 单个进程的 CPU 使用率计算，我们需要读取对应进程的 `/proc/[pid]/stat` 文件，将进程瞬时用户态和内核态的 ticks 数相加，就能得到进程的总 ticks。然后运用公式 “(进程的 ticks / 单个 CPU 总 ticks) * 100.0” 计算出进程 CPU 使用率的百分比值。

- 系统的 CPU 使用率，需要读取 `/proc/stat` 文件，得到瞬时各项 CPU 使用率的 ticks 值，相加得到一个总值，单项值除以总值就是各项 CPU 的使用率。

- 对于容器进程来说，在 `/sys/fs/cgroup/cpuacct/` 目录下有一个 `cpuacct.stat` 文件，里面记录了 `user 466  system 7109` 两个值，分别是这个控制组里所有进程的内核态 ticks 和用户态的 ticks。从每个容器的 CPU Cgroup 控制组里的 `cpuacct.stat` 的统计值中，可以比较快地得到整个容器的 CPU 使用率。
  
总结：
`/proc/stat` - 全局状态

`/proc/[pid]/stat` - 单个进程的状态

`cpuacct.stat` - 容器内的状态

## 平均负载

平均负载 Load average 的计算方式可以参考 `man uptime`。

> System load averages is the **average number of processes that are either in a runnable or uninterruptable state**. A process in a runnable state is either using the CPU or waiting to use the CPU. A process  in  uninterruptable state (D state shows from `ps` command) is waiting for some I/O access, eg waiting for disk. The averages are taken over the three time intervals. Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.

在 Linux 内核中有数百处调用点，它们会把进程设置为 D 状态，主要集中在 disk I/O 的访问和信号量（Semaphore）锁的访问上，因此 D 状态的进程在 Linux 里是很常见的。无论是对 disk I/O 的访问还是对信号量的访问，都是对 Linux 系统里的资源的一种竞争。**当进程处于 D 状态时，就说明进程还没获得资源**，这会在应用程序的最终性能上体现出来，也就是说用户会发觉应用的性能下降了。

为什么 CPU Cgroups 不能解决 D 状态进程导致的性能下降呢？因为 Cgroups 更多的是以进程为单位进行隔离，而 **D 状态进程是内核中系统全局资源引入的**，所以 Cgroups 影响不了它。

Idea：在生产环境中监控容器的宿主机节点里 D 状态的进程数量，然后对 D 状态进程数目异常的节点进行分析，比如磁盘硬件出现问题引起 D 状态进程数目增加，这时就需要更换硬盘。

> uptime，top 等 都属于 procps-ng 项目

## Memory Cgroup

问题 1：自己的容器在系统中被杀掉？

回答：容器中的进程使用了太多的内存。具体来说，就是容器里所有进程使用的内存量，超过了容器所在 Memory Cgroup 里的内存限制。这时 Linux 系统就会主动杀死容器中的一个进程，往往这会导致整个容器的退出。`docker inspect` 可以看到 `status` 是 exited，`OOMKilled` 为 true。

Linux 进程的内存申请策略是，Linux 允许进程在申请内存的时候是 overcommit 的，即允许进程申请超过实际物理内存上限的内存。overcommit 的内存申请模式可以带来一个好处，它可以**有效提高系统的内存利用率**。不过这也带来了一个问题，就是物理内存真的不够了，Linux 采取的措施就是杀死某个正在运行的进程。

问题 2：发生 OOM 的时候，Linux 到底是根据什么标准来选择被杀的进程呢？

答案：在 Linux 内核里有一个 **oom_badness()** 函数，它定义了选择进程的标准。判断标准主要是两点：第一，进程已经使用的物理内存页面数；第二，每个进程的 OOM 校准值 oom_score_adj。在 /proc 文件系统中，每个进程都有一个 `/proc/[pid]/oom_score_adj` 的接口文件。我们可以在这个文件中输入 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。计算公式如下所示，总结下来就是：用系统总的可用页面数，去乘以 OOM 校准值 oom_score_adj，再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。

```c
       adj = (long)p->signal->oom_score_adj;

       points = get_mm_rss(p->mm) + get_mm_counter(p->mm, MM_SWAPENTS) + mm_pgtables_bytes(p->mm) / PAGE_SIZE;

       adj *= totalpages / 1000;
       points += adj;
```

Memory Cgroup 的虚拟文件系统的挂载点一般在 `/sys/fs/cgroup/memory` 这个目录下，这个和 CPU Cgroup 类似。我们可以在 Memory Cgroup 的挂载点目录下，创建一个子目录作为控制组。

Memory Cgroup 中和 OOM 最相关的 3 个参数：`memory.limit_in_bytes`（所有进程可使用的最大内存），`memory.oom_control`（当达到最大内存的时候决定会不会触发 OOM） 和 `memory.usage_in_bytes` （只读参数，显示了当前控制组内的所有进程实际使用的内存总和）。

问题 3：容器因为 OOM 被杀，要如何处理呢？

回答：可以通过内核日志 (查看 `journalctl -k` 的输出或者 `/var/log/message` 中的信息) 做排查，查看容器里内存使用最多的进程，然后对它进行分析。解决思路**要么是提高容器的最大内存限制，要么需要具体去解决进程代码的 BUG**。

> `rss` 是 Resident Set Size 的缩写，指的就是进程真正在使用的物理内存页面数量。 rss * 4KB ≈ 实际使用的物理内存大小

## Page Cache

Linux 的内存类型：

- RSS（`top` 命令输出的 `RES` 列）包含了进程的代码段内存，栈内存，堆内存，共享库的内存。`malloc()`，`memset()` 函数申请的就是堆内存。

> 应用程序在申请内存的时候，比如说，调用 `malloc()` 来申请 100MB 的内存大小，`malloc()` 返回成功了，这时候系统其实只是把 100MB 的虚拟地址空间（`top` 命令输出的 `VIRT` 列）分配给了进程，但是并没有把实际的物理内存页面分配给进程。当进程对这块内存地址开始做真正读写操作的时候，系统才会把实际需要的物理内存分配给进程。而这个过程中，进程真正得到的物理内存，就是这个 RSS 了。

- Page Cache 如果进程对磁盘上的文件做了读写操作，Linux 还会分配内存，把磁盘上读写到的页面存放在内存中，这部分的内存就是 Page Cache。它的主要作用是提高磁盘文件的读写性能，因为系统调用 `read()` 和 `write()` 的缺省行为都会把读过或者写过的页面存放在 Page Cache 里。

> 如果应用申请内存，发现剩余物理内存不够了，Linux 就会根据自己的内存管理机制，选择一定的内存回收算法（e.g. LRU 最近最少使用）来决定哪些内存页面会被释放。Page Cache 只是起到 Cache 的作用，会被优先选择释放。

Memory Cgroup 控制组里 RSS 内存和 Page Cache 内存的和，正好是 `memory.usage_in_bytes` 的值。

当控制组里的进程需要申请新的物理内存，而且 `memory.usage_in_bytes` 里的值超过控制组里的内存上限值 `memory.limit_in_bytes`，这时 Linux 的内存回收（page frame reclaim）就会被调用起来。那么在这个控制组里的 page cache 的内存会根据新申请的内存大小释放一部分，这样还是能成功申请到新的物理内存，整个控制组里总的物理内存开销 `memory.usage_in_bytes` 还是不会超过上限值 `memory.limit_in_bytes`。

在 Memory Cgroup 中有一个参数 `memory.stat`，可以显示在当前控制组里各种内存类型的**实际开销**。判断容器真实的内存使用量，我们不能用 Memory Cgroup 里的 `memory.usage_in_bytes`，而需要用 `memory.stat` 里的 rss 值。

用 `free` 命令查看节点的可用内存，不能看 "free" 字段下的值，而要看除去 Page Cache 之后的 "available" 字段下的值。

## Swap 空间

Linux 中的 Swap 空间，简单来说就是一块磁盘空间。当内存写满的时候，就可以把内存中不常用的数据暂时写到这个 Swap 空间上。这样一来，内存空间就可以释放出来，用来满足新的内存申请的需求。它的好处是可以**应对一些瞬时突发的内存增大需求**，不至于因为内存一时不够而触发 OOM Killer，导致进程被杀死。

Linux 系统中 `/proc/sys/vm/swappiness` 参数与 Swap 空间存在一定的关系。Linux 内核文档中对 swappiness 的描述如下：

> swappiness: This control is used to define how aggressive(积极程度) the kernel will swap memory pages. Higher values will increase aggressiveness, lower values decrease the amount of swap. A value of 0 instructs the kernel not to initiate swap until the amount of free and file-backed pages is less than the high water mark in a zone.

> zone 是 Linux 划分物理内存的一个区域，里面有 3 个水位线（water mark），水位线可以用来警示空闲内存的紧张程度。其值可以在 `/proc/zoneinfo` 文件中找到。

swappiness 的取值范围在 0 到 100，值为 100 的时候系统平等回收匿名内存（`malloc` 分配的那部分内存）和 Page Cache 内存；一般缺省值为 60，就是优先回收 Page Cache；即使 swappiness 为 0，也不能完全禁止 Swap 分区的使用，就是说在内存紧张的时候，也会使用 Swap 来回收匿名内存。

在 Memory Cgroup 中有一个 `memory.swappiness` 参数，如果 Memory Cgroup 中的进程设置了 "memory.swappiness=0" 的话，那么这些进程就不会再使用 Swap 空间。通过这个参数可以让需要使用 Swap 空间的容器和不需要 Swap 的容器，同时运行在同一个宿主机上。

> 在 Memory Cgorup 的控制组里，如果设置了 `memory.swappiness` 参数，它就会覆盖全局的 swappiness，让全局的 swappiness 在这个控制组里不起作用。

> 当 "memory.swappiness=0" 的时候，对匿名页的回收是始终禁止的，也就是始终都不会使用 Swap 空间。这时 Linux 系统不会再去比较 free 内存和 zone 里的 high water mark 的值，再决定一个 Memory Cgroup 中的匿名内存要不要回收了。

## 容器文件系统

容器的文件系统采用的是 UnionFS 文件系统。它的好处是可以有效减少磁盘上冗余的镜像数据，减少冗余镜像数据在网络上的传输。它实现的主要功能是**把多个目录一起挂载到一个目录下**。

UnionFS 类似的实现有很多种，最早的时候 Docker 采用的是 AUFS，现在默认使用的是 OverlayFS。

```shell
#!/bin/bash
# Overlay example

umont ./merged
rm upper lower merged work -r

mkdir upper lower merged work
echo "I'm from lower" > lower/in_lower.txt
echo "I'm from upper" > upper/in_upper.txt
echo "I'm from lower" > lower/in_both.txt
echo "I'm from upper" > upper/in_both.txt

sudo mount -t overlay overlay \
  -o lowerdir=./lower,upperdir=./upper,workdir=./work \
  ./merged
```

OverlayFS 涉及到四个目录 `lower` `upper` `work` `merged`。`lower` 是最下层的，这一层里的文件不可以被修改，可以认为它是只读的，OverlayFS 支持多个 `lower` 层；`upper` 在 `lower` 的上一层，它里面的文件是可读写的，如果有文件创建，修改，删除，都会在这一层中表现出来；`merged` 层是用户实际看到的目录，用户的实际文件操作就是在这一层；`work` 层是存放临时文件的目录，修改文件产生的临时文件会放在这里。

从挂载点的视角看，`upper` 层的文件会覆盖 `lower` 层的文件，比如 "in_both.txt" 这个文件，在 `lower` 层和 `upper` 层都有，但是挂载点 `merged` 里看到的只是 `upper` 层里的 "in_both.txt"。

如果在 `merged` 层中对文件进行了以下的操作，（Copy on write）：

- 创建新文件，会出现在 `upper` 层。

- 删除文件，如果删除 "in_upper.txt" 那么这个文件会从 `upper` 目录中消失；如果删除 "in_lower.txt" 那么会在 `upper` 层中新增加一个文件标记 "in_lower.txt" 为已删除，不会出现在 `merged` 中，`lower` 层中不会消失。

- 修改文件，如果修改 "in_lower.txt"，那么就会在 `upper` 目录中新建一个 "in_lower.txt" 文件，包含更新的内容，而在 `lower` 中的原来的实际文件 "in_lower.txt" 不会改变。

> fio 命令计算文件性能：`fio -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=10G -numjobs=1  -name=./fio.test`。"-direct=1"，指采用非 buffered I/O 文件读写的方式；"-iodepth=64" 和 "-ioengine=libaio"，指文件读写采用异步 I/O（Async I/O）的方式；"-rw=read，-bs=4k，-size=10G"，指读测试，每次读 4KB，总共读 10G；"-numjobs=1"，指只有一个进程或线程在运行。

> 对于性能问题，可以使用 Linux 下的 `perf` 工具来查看。

## 容器文件配额

从宿主机的角度看，`upper` 就是一个目录，如果容器不断往容器文件系统中写入数据，实际上就是往宿主机的磁盘上写数据，这些数据也就存在于宿主机的磁盘目录中。对于容器来说，如果有大量的写操作是不建议写入容器文件系统的，一般是需要给容器挂载一个 volume，用来满足大量的文件读写。

Linux 上有两个最常用的文件系统 XFS 和 ext4，它们有一个特性叫 Quota，是可以限制一个目录的使用量。

XFS Quota

在 Linux 系统里的 XFS 文件系统缺省都有 Quota 的特性，这个特性可以为 Linux 系统里的一个用户（user），一个用户组（group）或者一个项目（project）来限制它们使用文件系统的额度（quota），也就是限制它们可以写入文件系统的文件总量。

因为同一个用户或者用户组可以操作多个目录，多个用户或者用户组也可以操作同一个目录，这样对一个用户或者用户组的限制，就很难用来限制一个目录。排除了限制用户或用户组的模式后，可以了解一下 Project 模式是怎么工作的。

- 使能 Quota：在文件系统挂载的时候加上 **pquota** 参数。对根目录来说，这个参数必须作为一个内核启动的参数"rootflags=pquota"，这样设置就可以保证根目录在启动挂载的时候，带上 XFS Quota 的特性并且支持 Project 模式。

- 查看 Quota：`cat /proc/mount | grep quota`

- 配置：
  
  ```
  mkdir -p /tmp/xfs_prjquota
  xfs_quota -x -c 'project -s -p /tmp/xfs_prjquota 101' /
  xfs_quota -x -c 'limit -p bhard=10m 101' /
  ```

- 原理：给目标目录打上一个 Project ID，这个 ID 最终是写到目录对应的 inode 上；在 XFS 文件系统中，需要给这个 project ID 设置一个写入数据块的限制。有了 ID 和限制值之后，文件系统就可以统计所有带这个 ID 文件的数据块大小总和，并且与限制值进行比较。一旦所有文件大小的总和达到限制值，文件系统就不再允许更多的数据写入了。

Docker 实现了限流功能，也就是用 XFS Quota 来限制容器的 OverlayFS 大小。就是在用 `docker run` 启动容器的时候，加上一个参数 `--storage-opt size=` ，就能限制住容器 OverlayFS 文件系统可写入的最大数据量了。

对于使用 OverlayFS 的容器，我们应该如何去防止它把宿主机的磁盘给写满呢？方法就是**对 OverlayFS 的 `upper` 目录做 XFS Quota 的限流**。

> `man xfs_quota`

## 磁盘限速

> IOPS 是 Input/Output Operations Per Second 的简称，数值越大越好。吞吐量（Throughput）是指每秒钟磁盘中数据的读取量，一般以 MB/s 为单位。在 IOPS 固定的情况下，如果读写的每一个数据块越大，那么吞吐量也越大，它们的关系大概是这样的：`吞吐量 = 数据块大小 * IOPS`。

在 Cgroup v1 中有 blkio 子系统，它可以来限制磁盘的 I/O。blkio Cgroup 的虚拟文件系统挂载点一般在 "/sys/fs/cgroup/blkio/"。

在 blkio Cgroup 中，有四个最主要的参数，它们可以用来限制磁盘 I/O 性能。

- `blkio.throttle.read_iops_device`, 磁盘读取 IOPS 限制，
- `blkio.throttle.read_bps_device`, 磁盘读取吞吐量限制，
- `blkio.throttle.write_iops_device`, 磁盘写入 IOPS 限制，
- `blkio.throttle.write_bps_device`, 磁盘写入吞吐量限制。

假设要对一个控制组做限制，限制它对磁盘 /dev/vdb 的写入吞吐量不超过 10MB/s，那么我们对 blkio.throttle.write_bps_device 参数的配置就是下面这个命令。

`echo "252:16 10485760" > $CGROUP_CONTAINER_PATH/blkio.throttle.write_bps_device` 256:16 是设备 /dev/vdb 的主次设备号，可以用过 `ls -l /dev/vdb` 查到。

在给每个容器都加了 blkio Cgroup 限制，限制为 10MB/s 后，即使两个容器同时在一个磁盘上写入文件，那么每个容器的写入磁盘的最大吞吐量，也不会互相干扰了。

>  `iostat` 可以查看实际的磁盘写入速度

问题：当让 fio 运行在 Buffered I/O 模式的时候，观察 fio 执行的输出。会发现，即使设置了 blkio Cgroup，也根本不能限制磁盘的吞吐量了。

回答：这与 Linux 的两种文件模式 `Direct I/O` 和 `Buffered I/O` 有关。Direct I/O 模式，用户进程如果要写磁盘文件，就会通过 Linux 内核的文件系统层 (filesystem) -> 块设备层 (block layer) -> 磁盘驱动 -> 磁盘硬件，这样一路下去写入磁盘。而如果是 Buffered I/O 模式，那么用户进程只是把文件数据写到内存中（Page Cache）就返回了，而 Linux 内核自己有线程会把内存中的数据再写入到磁盘中。

在 Cgroup v1 下，会发现 Direct I/O 可以通过 blkio Cgroup 来限制磁盘 I/O，但是 Buffered I/O 不能被限制。这是由于在 v1 版本中，它的每一个子系统都是独立的，资源的限制只发生在子系统中。当一个进程的 blkio 属于一个 group，而它的 memory 属于另一个 group 的时候，Page Cache 的页面在刷入磁盘的时候，产生的 I/O 不会被计算到进程上面。

Cgroup v2 相比 Cgroup v1 做的最大的变动就是**一个进程属于一个控制组，而每个控制组里可以定义自己需要的多个子系统**。

常规的 Linux 中仍将 v1 当作默认的 Cgroup，如果要打开 Cgroup v2，就需要配置一个内核参数 `cgroup_no_v1=blkio,memory`。

测试打开 v2 后，fio 在 Buffered I/O 下是否被限速：

``` shell
# Create a new control group
mkdir -p /sys/fs/cgroup/unified/iotest

# enable the io and memory controller subsystem
echo "+io +memory" > /sys/fs/cgroup/unified/cgroup.subtree_control

# Add current bash pid in iotest control group.
# Then all child processes of the bash will be in iotest group too,
# including the fio

echo $$ >/sys/fs/cgroup/unified/iotest/cgroup.procs

# 256:16 are device major and minor ids, /mnt is on the device.
echo "252:16 wbps=10485760" > /sys/fs/cgroup/unified/iotest/io.max
cd /mnt

#Run the fio in non direct I/O mode
fio -iodepth=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=./fio.test
```

> Cgoupv2 io+Memory 两个子系统一起使用，就可以对 buffered I/O 控制磁盘写入速率。

## 内存与 IO

问题：当使用 Buffered I/O 的应用程序从虚拟机迁移到容器，这时会发现多了 Memory Cgroup 的限制之后，write() 写相同大小的数据块花费的时间，延时波动会比较大？

回答：猜测是不是与 dirty pages 有关，尝试：在节点是大内存容量，并且 dirty_ratio 为系统缺省值 20%，dirty_background_ratio 是系统缺省值 10% 的情况下，通过观察 `/proc/vmstat` 中的 `nr_dirty` 数值可以发现，dirty pages 不会阻塞进程的 Buffered I/O 写文件操作。调试：使用 `perf` 和 `ftrace` 工具对容器中的写文件进程进行 profile。用 `perf` 得到了系统调用 `write()` 在内核中的一系列子函数调用，再用 `ftrace` 来查看这些子函数的调用时间。根据 `ftrace` 的结果，发现写数据到 Page Cache 的时候，需要不断地去释放原有的页面，这个时间开销是最大的。造成容器中 Buffered I/O write() 不稳定的原因，正是**容器在限制内存之后，Page Cache 的数量较小并且不断申请释放**。

Buffered I/O 模式下，写入了数据的内存页面，但还没被写入到磁盘文件之前的数据就被叫作 dirty pages。与 dirty pages 相关的参数位于 `/proc/sys/vm` 中。

- `dirty_bytes`，用来定义 dirty pages 的内存临界值。同下面 `dirty_background_ratio` 和 `dirty_background_bytes` 的关系。

- `dirty_ratio`，默认值是 20，意味着当 dirty pages 占用的内存 / 节点内存总值 的结果大于 20% 的话，正在执行 Buffered I/O 写文件的进程就会被阻塞住，直到它写的数据页面都写到磁盘为止。

- `dirtytime_expire_seconds`

- `dirty_background_ratio`，默认值是 10，意味着当 dirty pages 占用的内存 / 节点内存总值 的结果大于 10% 的话，内核 flush 线程就把 dirty pages 刷到磁盘里。

- `dirty_background_bytes`，用来定义 dirty pages 的临界值。它和 `dirty_background_ratio` 两个值，只能有一个起作用，定义了一个，另一个就会归 0。

- `dirty_expire_centisecs`，默认值是 3000，单位为百分之一秒，定义了 dirty page 在内存中存放的最长时间，如果一个 dirty page 超过这里定义的时间，那么内核的 flush 线程也会把这个页面写入磁盘。

- `dirty_writeback_centisecs`，默认值是 500，单位为百分之一秒，表示每 5 秒钟会唤醒内核的 flush 线程来处理 dirty pages。

用 `perf` 和 `ftrace` 调试的过程：

1. 容器启动后在宿主机上得到这个进程的 pid，使用 `perf record -a -g -p <pid>`，记录执行过程。
   
2. 使用 `perf report` 查看结果。
   
3. 把主要的函数写入到 `ftrace` 的 set_ftrace_filter 里，然后把 `ftrace` 的 tracer 设置为 function_graph，并且打开 tracing_on 开启追踪。
   
   ``` shell
   # cd /sys/kernel/debug/tracing
   # echo vfs_write >> set_ftrace_filter
   # echo xfs_file_write_iter >> set_ftrace_filter
   # echo xfs_file_buffered_aio_write >> set_ftrace_filter
   # echo iomap_file_buffered_write
   # echo iomap_file_buffered_write >> set_ftrace_filter
   # echo pagecache_get_page >> set_ftrace_filter
   # echo try_to_free_mem_cgroup_pages >> set_ftrace_filter
   # echo try_charge >> set_ftrace_filter
   # echo mem_cgroup_try_charge >> set_ftrace_filter
   
   # echo function_graph > current_tracer
   # echo 1 > tracing_on
   ```

4. 从 `ftrace` 的 trace_pipe 中读取出追踪到的这些函数。
   
从结果可以看出：当需要申请 Page Cache 页面的时候，`write()` 系统调用会反复地调用 `mem_cgroup_try_charge()`，并且在释放页面的时候，函数 `do_try_to_free_pages()` 花费的时间特别长，有 50+us（时间单位，micro-seconds）这么多。

Linux 会把所有的空闲内存利用起来，一旦有 Buffered I/O，这些内存都会被用作 Page Cache。当容器加了 Memory Cgroup 限制了内存之后，对于容器里的 Buffered I/O，就只能使用容器中允许使用的最大内存来做 Page Cache。那么如果容器在做内存限制的时候，Cgroup 中 **`memory.limit_in_bytes` 设置得比较小，而容器中的进程又有很大量的 I/O**，这样申请新的 Page Cache 内存的时候，又会不断释放老的内存页面，这些操作就会带来额外的系统开销了。

> 在对容器做 Memory Cgroup 限制内存大小的时候，不仅要考虑容器中**进程实际使用的内存量，还要考虑容器中程序 I/O 的量**，合理预留足够的内存作为 Buffered I/O 的 Page Cache。

> 还有一个解决思路是，在程序中自己管理文件的 cache 并且调用 Direct I/O 来读写文件。

## 容器网络

在容器中运行的应用程序，如果需要用到 tcp/ip 协议栈的话，常常需要修改一些网络参数（内核中网络协议栈的参数）。很大一部分网络参数都在 `/proc` 文件系统下的 `/proc/sys/net/` 目录里。

两种修改方式：一是直接在 `/proc/sys/net/` 目录里修改参数；二是用 `sysctl` 命令来修改。

`man network_namespaces` 可以看到 Network Namespace 虚拟了以下的资源：网络设备（物理的或者虚拟的），ipv4 和 ipv6 协议栈，路由表，防火墙规则（iptables 规则），网络的状态信息（在 `/proc/PID/net`, `/sys/class/net` 和 `/proc/sys/net` 下的信息）。

> Network namespaces provide isolation of the system resources associated with networking: network devices, IPv4 and IPv6 protocol stacks, IP routing tables, firewall rules, the /proc/net directory (which is a symbolic link to /proc/PID/net), the /sys/class/net directory, various files under /proc/sys/net, port numbers (sockets), and so on. In addition, network namespaces isolate the UNIX domain abstract socket namespace (see unix(7)).

如何创建一个 Network Namespace：

1. 创建新进程的时候通过 `clone()` 系统调用并带上 `CLONE_NEWNET` flag
   ```c
   int new_netns(void* para) {
       printf("New namespace devices: \n");
       system("ip link");
       printf("\n\n");
       
       sleep(100);
       return 0;
   }

   int main(void) {
       pid_t pid;
       printf("Host namespace devices: \n");
       system("ip link");
       printf("\n\n");

       pid = clone(new_netns, stack + STACK_SIZE, CLONE_NEWNET | SIGCHLD, NULL);
       if (pid == -1) {
              errExit("clone");
       }
       if (waitpid(pid, NULL, 0) == -1) {
              errExit("waitpid");
       }
       return 0;
   }
   ```

2. 通过 `unshare()` 系统调用创建
   
   ```c
   int main(void) {
       pid_t pid;
       if (unshare(CLONE_NEWNET) == -1) {
              errExit("unshare");
       }
       return 0;
   }
   ```

3. 使用 `ip netns` 命令创建

`lsns` 可以查看有哪些 namespace，`lsns -t net` 查看 Network Namespace。`nsenter` 可以进入到某个 namespace，`nsenter [options] [program [arguments]]` (Enters the namespaces of one or more other processes and then executes the specified program.)

Network namespace 中的网络参数，一部分是从 host 复制过来的，一部分是在容器启动之后初始化的。如果想要修改这些参数，可以在容器启动的时候加 `--sysctl` 参数，e.g. `docker run -d --name net_para --sysctl net.ipv4.tcp_keepalive_time=600`。

> runC 当初出于安全的考虑，把容器中所有 /proc 和 /sys 相关的目录缺省都做了 read-only mount 的处理。同时 runC 也在对 /proc/sys 目录做 read-only mount 之前，预留出了修改接口，Docker 的 `–-sysctl` 或者 k8s 里的`allowed-unsafe-sysctls` 特性也都利用了 runC 的 sysctl 参数修改接口，允许容器在启动时修改容器 Namespace 里的参数。

## 容器网络不通

对于容器从自己的 Network Namespace 连接到 Host Network Namespace 的方法，一般来说就只有两类设备接口：一类是 veth，另外一类是 macvlan/ipvlan。

用 `ip netns` 命令模拟 veth 接口

```shell
pid=$(ps -ef | grep "test" | grep -v grep | awk '{print $2}')
echo $pid
ln -s /proc/$pid/ns/net /var/run/netns/$pid

# Create a pair of veth interfaces
ip link add name veth_host type veth peer name veth_container
# Put one of them in the new net ns
ip link set veth_container netns $pid

# In the container, setup veth_container
ip netns exec $pid ip link set veth_container name eth0
ip netns exec $pid ip addr add 172.17.1.2/16 dev eth0
ip netns exec $pid ip link set eth0 up
ip netns exec $pid ip route add default via 172.17.0.1

# In the host, set veth_host up
ip link set veth_host up
```

> 在 "/var/run/netns/" 的目录下建立一个符号链接，指向这个容器的 Network Namespace，在后面的 "ip netns" 操作里，就可以用 pid 的值作为这个容器的 Network Namesapce 的标识了。

数据包到了 Host Network Namespace 之后呢，怎么把它从宿主机上的 eth0 发送出去? 其实就是一个普通 Linux 节点上数据包转发的问题。解决问题的方法有很多种，比如说用 nat 来做个转发，或者建立 Overlay 网络发送，也可以通过配置 proxy arp 加路由的方法来实现。

> 遇到容器中网络不通的情况，先要理解自己的容器以及容器在宿主机上的配置，通过对主要设备上做 tcpdump 可以找到具体在哪一步数据包停止了转发。然后结合内核网络配置参数，路由表信息，防火墙规则等来定位问题。

## 容器网络延时

之前运行在物理机器上，现在迁移到容器上的，如果网络配置采用 veth 方式，就会出现网络延时增加的现象。可以使用 `netperf`（Netperf 是一个衡量网络性能的工具，它可以提供单向吞吐量和端到端延迟的测试）来模拟一下。

可以运行 `netperf` 的 `TCP_RR` 测试用例，`TCP_RR` 是 `netperf` 里专门用来测试网络延时的，缺省每次运行 10 秒钟。运行以后，计算平均每秒钟 TCP request/response 的次数，这个次数越高，就说明延时越小。

虽然 veth 是一个虚拟的网络接口，但是在接收数据包的操作上，这个虚拟接口和真实的网路接口并没有太大的区别。这里除了没有硬件中断的处理，其他操作都差不多，特别是**软中断（softirq）**的处理部分其实就和真实的网络接口是一样的。

Linux 内核里的 veth 的驱动代码（drivers/net/veth.c）

```c
static netdev_tx_t veth_xmit(struct sk_buff *skb, struct net_device *dev)
{
…
       /* 拿到veth peer设备的net_device */
       rcv = rcu_dereference(priv->peer);
…
       /* 将数据送到veth peer设备 */ 
       if (likely(veth_forward_skb(rcv, skb, rq, rcv_xdp) == NET_RX_SUCCESS)) {

…
}

static int veth_forward_skb(struct net_device *dev, struct sk_buff *skb,
                            struct veth_rq *rq, bool xdp)
{
        /* 这里最后调用了 netif_rx() */
        return __dev_forward_skb(dev, skb) ?: xdp ?
                veth_xdp_rx(rq, skb) :
                netif_rx(skb);
}
```

`netif_rx()` 是一个网络设备驱动里面标准的接收数据包的函数，`netif_rx()` 里面会为这个数据包 raise 一个 softirq。

> 在处理网络数据的时候，一些运行时间较长而且不能在硬中断中处理的工作，就会通过 softirq 来处理。一般在硬件中断处理结束之后，网络 softirq 的函数才会再去执行没有完成的包的处理工作。即使这里 softirq 的执行速度很快，还是会带来额外的开销。

根据 veth 这个虚拟网络设备的实现方式，可以看到它必然会带来额外的开销，这样就会增加数据包的网络延时。

除了 veth 之外，容器还可以选择其他的网络配置方式。macvlan 和 ipvlan 等。

为容器手动配置上 ipvlan 的网络接口。

```shell
docker run --init --name lat-test-1 --network none -d registry/latency-test:v1 sleep 36000

pid1=$(docker inspect lat-test-1 | grep -i Pid | head -n 1 | awk '{print $2}' | awk -F "," '{print $1}')
echo $pid1
ln -s /proc/$pid1/ns/net /var/run/netns/$pid1
 
ip link add link eth0 ipvt1 type ipvlan mode l2
ip link set dev ipvt1 netns $pid1

ip netns exec $pid1 ip link set ipvt1 name eth0
ip netns exec $pid1 ip addr add 172.17.3.2/16 dev eth0
ip netns exec $pid1 ip link set eth0 up
```

从 ipvlan 接口的发送代码中可以看到，如果是往宿主机外发送数据，发送函数会直接找到 ipvlan 虚拟接口对应的物理网络接口。直接调用物理网卡的 `dev_queue_xmit()`，通过物理接口把数据直接发送出去。

> 对于延时敏感的应用程序，我们可以考虑使用 ipvlan/macvlan 网络接口的容器。不过，由于 ipvlan/macvlan 网络接口直接挂载在物理网络接口上，对于需要使用 iptables 规则的容器，比如 Kubernetes 里使用 service 的容器，就不能工作了。这就需要你结合实际应用的需求做个判断，再选择合适的方案。

## 容器网络重传

`netstat -s` 可以显示每一个协议的统计（Display summary statistics for each protocol）。`netstat -s | grep retran` 可以查看重传的段有多少。

问题：用户把他们的应用程序从物理机迁移到容器之后，从网络监控中发现，为什么**容器中数据包的重传的数量要比在物理机里高了不少**？

回答：可能与 veth 接口没有启用 rps 配置有关，也可能与 `/proc/sys/net/ipv4/tcp_reordering` 等虚拟协议栈中的参数配置有关。

TCP 协议定义了快速重传 （fast retransmit）的概念。它的基本定义是这样的：如果发送端收到 3 个重复的 ACK，那么发送端就可以立刻重新发送 ACK 对应的下一个数据包。

虽然 TCP 快速重传的标准定义是需要收到 3 个重复的 Ack，不过你会发现在 Linux 中常常收到一个 Dup Ack 后，就马上重传数据了。这是什么原因呢？

因为 Linux 用到了 SACK 也就是选择性确认（Selective Acknowledgement）。与普通的 ACK 相比，SACK 会把接收端收到的所有包的序列信息，都反馈给发送端。有了 SACK，对于发送端来说，在收到 SACK 之后就已经知道接收端收到了哪些数据，没有收到哪些数据。

问题：如果 netstat 中有大量的 "fast retransmits" 意味着什么？

回答：其实在云平台的这种网络环境里，网络包乱序 + SACK 之后，产生的数据包重传的量要远远高于网络丢包引起的重传。

通过 veth 接口从容器向外发送数据包，会触发 peer veth 设备去接收数据包，这个接收的过程就是一个网络的 softirq 的处理过程。在触发 softirq 之前，veth 接口会模拟硬件接收数据的过程，通过 `enqueue_to_backlog()` 函数把数据包放到某个 CPU 对应的数据包队列里（softnet_data）。

```c
static int netif_rx_internal(struct sk_buff *skb)
{
        int ret;

        net_timestamp_check(netdev_tstamp_prequeue, skb);

        trace_netif_rx(skb);

#ifdef CONFIG_RPS
        if (static_branch_unlikely(&rps_needed)) {
                struct rps_dev_flow voidflow, *rflow = &voidflow;
                int cpu;

                preempt_disable();
                rcu_read_lock();

                cpu = get_rps_cpu(skb->dev, skb, &rflow);
                if (cpu < 0)
                        cpu = smp_processor_id();

                ret = enqueue_to_backlog(skb, cpu, &rflow->last_qtail);

                rcu_read_unlock();
                preempt_enable();
        } else
#endif
        {
                unsigned int qtail;

                ret = enqueue_to_backlog(skb, get_cpu(), &qtail);
                put_cpu();
        }
        return ret;
}
```

在缺省的状况下（也就是没有 RPS 的情况下），`enqueue_to_backlog()` 把数据包放到了“当前运行的 CPU”（`get_cpu()`）对应的数据队列中。如果是从容器里通过 veth 对外发送数据包，那么这个“当前运行的 CPU”就是容器中发送数据的进程所在的 CPU。

对于多核的系统，这个发送数据的进程可以在多个 CPU 上切换运行。进程在不同的 CPU 上把数据放入队列并且 raise softirq 之后，因为每个 CPU 上处理 softirq 是个异步操作，所以两个 CPU network softirq handler 处理这个进程的数据包时，处理的先后顺序并不能保证。所以，**veth 对的这种发送数据方式增加了容器向外发送数据出现乱序的几率**。

问题：对于 veth 接口的这种发包方式，有办法减少一下乱序的几率吗？

回答：在网卡硬件中，可以根据数据包的 4 元组或者 5 元组信息来保证同一个数据流，比如一个 TCP 流的数据始终在一个 RX 队列中，这样可以保证同一流不会出现乱序的情况。而 RPS 就是在软件层面实现了类似的功能。

从上面的代码可以看出，如果对应的 veth 接口上打开了 RPS 的配置以后，那么对于同一个数据流，就可以始终选择同一个 CPU 了。

> 打开 RPS 的方法是修改网络接口设备队列中的 `/sys/devices/virtual/net/vethxxx/queues/rx-0/rps_cpus` 的值即可。`rps_cpus` 是一个 16 进制的数，每个 bit 代表一个 CPU。

## 容器安全之 capabilities

问题：用缺省 `docker run` 的方式启动容器后，在容器里很多操作都是不允许的，即使是以 root 用户来运行程序也不行？

回答：启动容器有一个"privileged"的参数。Privileged 的容器也就是允许容器中的进程可以执行所有的特权操作。因为安全方面的考虑，容器缺省启动的时候，哪怕是容器中 root 用户的进程，系统也只允许了 15 个 capabilities。

> 查看 Linux capabilities 相关的内容。`man capabilities`

所有的 capabilities 都在 Linux capabilities 的手册列出来了，也可以在内核的文件 `capability.h` 中看到所有 capabilities 的定义。

对于任意一个进程，在做任意一个特权操作的时候，都需要有这个特权操作对应的 capability。

在普通 Linux 节点上，非 root 用户启动的进程缺省没有任何 Linux capabilities，而 root 用户启动的进程缺省包含了所有的 Linux capabilities。

e.g. 运行 `iptables` 命令，对应的进程需要有 CAP_NET_ADMIN 这个 capability； `mount` 一个文件系统，那么对应的进程需要有 CAP_SYS_ADMIN 这个 capability。

`/proc/[pid]/status` 文件中有五个和 Cap 相关的参数:

- CapInh - Masks of capabilities enabled in inheritable. 

- CapPrm - Masks of capabilities enabled in permitted.

- CapEff - Masks of capabilities enabled in effective sets. 每一个 bit 代表一项 capability 是否被打开。

- CapBnd - Capability bounding set.

- CapAmb - Ambient capability set.

REF: [Capabilities: Why They Exist and How They Work](https://blog.container-solutions.com/linux-capabilities-why-they-exist-and-how-they-work)
[Linux Capabilities in Practice](https://blog.container-solutions.com/linux-capabilities-in-practice)

如果容器里需要使用 iptables。因为使用 iptables 命令，只需要设置 CAP_NET_ADMIN 这个 capability 就行。那么我们只要在运行 Docker 的时候，给这个容器再多加一个 NET_ADMIN 参数就可以了。

`docker run --name iptables --cap-add NET_ADMIN -it registry/iptables:v1 bash`

## 容器安全之 root 用户

由于容器和宿主机是共享 Linux 内核的，一旦软件有漏洞，那么容器中以 root 用户运行的进程就有机会去修改宿主机上的文件。

- Run as non-root user（给容器指定一个普通用户）。`docker run -ti --name root_example -u 6667:6667 -v /etc:/mnt  centos bash` 或者在 Dockerfile 中定义 USER。
  
  在一台 Linux 系统上，每个用户下的资源是有限制的，比如打开文件数目（open files）、最大进程数目（max user processes）等等。一旦有很多个容器共享一个 uid，这些容器就很可能很快消耗掉这个 uid 下的资源，这样很容易导致这些容器都不能再正常工作。

  要解决这个问题，必须要有一个云平台级别的 uid 管理和分配，但选择这个方法也要付出代价。因为这样做是可以解决问题，但是用户在定义自己容器中的 uid 的时候，他们就需要有额外的操作，而且平台也需要新开发对 uid 平台级别的管理模块，完成这些事情需要的工作量也不少。

- User Namespace（用户隔离技术的支持）。`podman run -ti  -v /etc:/mnt --uidmap 0:2000:1000 centos bash` (容器 uid 从 0 开始，对应于宿主机上从 2000 开始的 1000 个) "ns_uid:host_uid:amount"。
  
  它把容器中 root 用户（uid 0）映射成宿主机上的普通用户。对于用户在容器中自己定义普通用户 uid 的情况，我们只要为每个容器在节点上分配一个 uid 范围，就不会出现在宿主机上 uid 冲突的问题了。

- rootless container（以非 root 用户启动和管理容器）。启动容器的时候，Docker 或者 podman 是以非 root 用户来执行的。

## 案例分析：怎么解决海量IPVS规则带来的网络延时抖动问题？

找到 Linux 内核接收和发送数据包的主要函数，给每个数据包在内核协议栈的关键函数上打上时间戳，计算数据包在两个函数之间的时间差，时间差比较大的，说明问题就出在这两个函数之间。

在不修改内核源代码的情况，要**截获内核函数**，我们可以利用 `kprobe` 或者 `tracepoint` 的接口。可以直接写 kernel module 来调用 kprobe 或者 tracepoint 的接口，或者通过 ebpf 的接口来调用它们。

一是 ebpf 的程序在内核中加载会做很严格的检查，在生产环境中使用比较安全；二是 ebpf map 功能可以方便地进行内核态与用户态的通讯，实现一个工具也比较容易。

对于查找**高 CPU 使用率**情况下的热点函数，`perf` 是最有力的工具。`perf record -C 32 -g -- sleep 10` # 查看 CPU32 上的函数调用的热度。

对于查看**内核函数的调用时间**，可以用 `ftrace`, 把 `ftrace` 的 tracer 设置为 function_graph。

## perf 性能分析

通过抓取数据、数据读取和异常聚焦三个步骤来实现：

- 抓取数据：`perf record -C 32 -g -- sleep 10` # 抓取 CPU32 上的执行指令，记录函数调用关系（call-graph enable），抓取 10 秒。可以用 `FlameGraph` 工具来生成火焰图，方便查看。

- 读取数据：`perf report`

- 聚焦异常：`ftrace`

安装：`apt install linux-tools-common` `yum install perf` ...

命令：

- `perf list` - List all symbolic event types。有三个主要的 event，它们分别是 Hardware event、Software event 还有 Tracepoints event。
  
  - Hardware event：与底层处理器相关的行为。e.g. cpu-cycles、执行完成的 instructions、Cache 相关的 cache-misses 等。
  
  - Software event：定义在 Linux 内核代码中的几个特定的事件。e.g. 进程上下文切换（内核态到用户态的转换）事件 context-switches、发生缺页中断的事件 page-faults 等。
  
  - Tracepoints event：内核中很多关键函数里都有 Tracepoints。它的实现方式和 Software event 类似，都是在内核函数中注册了 event。

- `perf stat [-e <EVENT>] [-a] <command>` - Run a command and gather performance counter statistics from it。
  
- `perf record [-e <EVENT> | --event=EVENT] [-a] <command>` - Run a command and record its profile into perf.data.
  
  - `perf record -e cycles -c 10000 -- sleep 1` -  `-c` 参数可以指定每发生多少次，就做一次记录。

  - `perf record -e cycles -F 99 -- sleep 1` - `-F` 表示每分钟采样 99 次。
  
- `perf report` - Read perf.data (created by perf record) and display the profile.

如何在 Linux kernel 源代码里编译静态链接的 perf

```shell
# cd $(KERNEL_SRC_ROOT)/tools/perf
# vi Makefile.perf
  #### ADD “LDFLAGS=-static” in Makefile.perf
# make clean; make
```

在定位 CPU Uage 异常时最常用的方法，常规的步骤一般是这样的：

首先，调用 `perf record` 采样几秒钟，一般需要加 `-g` 参数，也就是 call-graph，还需要抓取函数的调用关系。在多核的机器上，还要记得加上 `-a` 参数，保证获取所有 CPU Core 上的函数运行情况。至于采样数据的多少，可以用 -c 或者 -F 参数来控制。接着，运行 `perf report` 读取数据。不过很多时候，为了更加直观地看到各个函数的占比，可以用 `perf script` 命令把 `perf record` 生成的 perf.data 转化成分析脚本，然后用 FlameGraph 工具来读取这个脚本，生成火焰图。

```shell
# perf record -a -g -- sleep 60
# perf script > out.perf
# git clone --depth 1 https://github.com/brendangregg/FlameGraph.git
# FlameGraph/stackcollapse-perf.pl out.perf > out.folded
# FlameGraph/flamegraph.pl out.folded > out.sv
```

Perf 的实现基础是 event，有两大类，一类是基于硬件 PMU 的，一类是内核中的软件注册。

Perf 在使用时的工作方式有两大类，计数和采样。

- 计数：`perf stat`，用来查看每种 event 发生的次数；
  
- 采样：`perf record`，它可以使用 period 方式，就是每 N 个 event 发生后记录一次 event 发生时的 IP / 进程信息，或者用 frequency 方式，每秒钟以固定次数来记录信息。记录的信息会存在当前目录的 perf.data 文件中。

在容器中使用 perf，要注意这两点：

1. 容器中的 perf 版本要和宿主机内核版本匹配，可以直接从源代码编译出静态链接的 perf。

2. 需要解决两个权限的问题，一个是 `seccomp` 对系统调用的限制，还有一个是内核对容器中没有 `SYC_ADMIN capability` 的限制。

## ftrace 函数追踪

ftrace - Function Tracer

ftrace 的操作都可以在 tracefs 这个虚拟文件系统中完成。`mount | grep tracefs` 查看是否 enable ftrace。

可以进入到 /sys/kernel/debug/tracing 目录下，看一下这个目录下的文件。

tracefs 虚拟文件系统下的文件操作，其实和我们常用的 Linux proc 和 sys 虚拟文件系统的操作是差不多的。通过对某个文件的 echo 操作，我们可以向内核的 ftrace 系统发送命令，然后 cat 某个文件得到 ftrace 的返回结果。

- 在缺省的状态下 ftrace 的 tracer 是 nop，也就是 ftrace 什么都不做。
  
- 执行 `echo function > current_tracer` 来告诉 ftrace，启用 function tracer。

- 向 `set_ftrace_filter` 文件写入想看到的内核函数，或者通过向 `set_ftrace_pid` 写入想看到的进程。

- 执行 `echo 1 > options/func_stack_trace` 来完整的函数调用栈。

- 执行 `echo function_graph > current_tracer` 把 current_tracer 设置为 function_graph，然后就能看到具体函数调用的时间。

例子：查看 kfree_skb() 这个函数是怎么执行的，就可以像下面这样配置：

```shell
# echo kfree_skb > set_graph_function    ### 设置 kfree_skb()
# echo nop > current_tracer              ### 暂时把 current_tracer 设置为 nop, 这样可以清空 trace
# echo function_graph > current_tracer   ### 把 current_tracer 设置为 function_graph
# cat trace | less                       ### 查看 trace 结果
```

ftrace 的实现机制

- high level 的架构，用户通过 tracefs 向内核中的 function tracer 发送命令，然后 function tracer 把收集到的数据写入一个 ring buffer，再通过 tracefs 输出给用户。

- 具体实现是 ftrace 是利用了 gcc 编译器的特性，再加上几步代码段替换操作，就完美地实现了对内核中所有函数追踪的接口（这里的“所有函数”不包括“inline 函数”）。

Linux 内核在编译的时候，缺省会使用三个 gcc 的参数 `-pg -mfentry -mrecord-mcount`。"-pg -mfentry" 这两个参数的作用是，给编译出来的每个函数开头都插入一条指令 "callq ", "-mrecord-mcount" 参数在最后的内核二进制文件 vmlinux 中附加了一个 mcount_loc 的段，这个段里记录了所有 "callq " 指令的地址。

尽管通过编译的方式，可以给每个函数都加上一个额外的 hook 点，但是这个额外 "fentry" 函数调用的开销是很大的。即使 "fentry" 函数中只是一个 retq 指令，也会使内核性能下降 13%。

所以 ftrace 在内核启动的时候做了一件事，就是把内核每个函数里的第一条指令 "callq "（5 个字节），替换成了 "nop" 指令（0F 1F 44 00 00），也就是一条空指令，表示什么都不做，相当于给每个函数预留了 5 个字节，这样在需要的时候，内核可以再把这 5 个字节替换成 callq 指令，call 的函数就可以指定成我们需要的函数了。

另外，在内核启动初始化的时候，ftrace 还申请了新的内存来存放 mcount_loc 段中原来的地址信息，外加对每个地址的控制信息，最后释放了原来的 mcount_loc 段。

## tracepoint 和 kprobe

tracepoint 其实就是在编译后的 Linux 内核中的一些关键函数中埋下的**固定的 hook 点**，这样在 tracing 的时候，我们就可以在这些固定的点上挂载调试的函数，然后查看内核的信息。

`perf list | grep Tracepoint` 查看所有的 tracepoint。同样在 tracefs 文件系统下也能看到所有的 tracepoint，`find /sys/kernel/debug/tracing/events -type d`。

例子：内核函数 `do_sys_open()` 中有一个 `trace_do_sys_open()` 调用，它其实就是一个 trace point。

```c
long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)
{
        struct open_flags op;
        int fd = build_open_flags(flags, mode, &op);
        struct filename *tmp;

        if (fd)
                return fd;

        tmp = getname(filename);
        if (IS_ERR(tmp))
                return PTR_ERR(tmp);

        fd = get_unused_fd_flags(flags);
        if (fd >= 0) {
                struct file *f = do_filp_open(dfd, tmp, &op);
                if (IS_ERR(f)) {
                        put_unused_fd(fd);
                        fd = PTR_ERR(f);
                } else {
                        fsnotify_open(f);
                        fd_install(fd, f);
                        trace_do_sys_open(tmp->name, flags, mode);
                }
        }
        putname(tmp);
        return fd;
}
```

可以用 `perf stat -a -e fs:do_sys_open -- sleep 10` 统计 10 秒钟内调用 `do_sys_open()` 成功的次数。如果在 tracefs 文件系统中，把 do_sys_open 的 tracepoint 打开 `echo 1 > events/fs/do_sys_open/enable`，就会看到每次调用 do_sys_open 成功时，打开的文件名，进程，文件属性等信息。

Tracepoint 是在内核中固定的 hook 点，并不是在所有的函数中都有 tracepoint。这时候就需要用到 kprobe。kprobe 可以**动态地**在所有的内核函数（除了 inline 函数）上挂载 probe 函数。

对于 `do_sys_open()` 函数中的 `do_filp_open()` 函数，可以通过 `perf probe` 添加 trace 点，然后用 `perf stat` 看看在 10 秒钟的时间里，这个函数被调用到的次数。

```shell
# perf probe --add do_filp_open
# perf stat -a -e probe:do_filp_open -- sleep 10
```

也可以通过 ftrace 的 tracefs 给 `do_filp_open()` 添加一个 kprobe event，这样就能查看 `do_filp_open()` 每次被调用的时候，前面两个参数的值了。

```shell
# echo 'p:kprobes/myprobe do_filp_open dfd=+0(%di):u32 pathname=+0(+0(%si)):string' > /sys/kernel/debug/tracing/kprobe_event
# 在函数被调用的时候，%di 存放了第一个参数，%si 存放的是第二个参数。
# enable
# echo 1 > /sys/kernel/debug/tracing/events/kprobes/myprobe/enable
# cat /sys/kernel/debug/tracing/trace
```

Tracepoint 原理，Linux 中，每一个 tracepoint 的相关数据结构和函数，主要是通过 `DEFINE_TRACE` 和 `DECLARE_TRACE` 这两个宏来定义的。

```c
#define DEFINE_TRACE_FN(_name, _reg, _unreg, proto, args)		\
	static const char __tpstrtab_##_name[]				\
	__section("__tracepoints_strings") = #_name;			\
	extern struct static_call_key STATIC_CALL_KEY(tp_func_##_name);	\
	int __traceiter_##_name(void *__data, proto);			\
	struct tracepoint __tracepoint_##_name	__used			\
	__section("__tracepoints") = {					\
		.name = __tpstrtab_##_name,				\
		.key = STATIC_KEY_INIT_FALSE,				\
		.static_call_key = &STATIC_CALL_KEY(tp_func_##_name),	\
		.static_call_tramp = STATIC_CALL_TRAMP_ADDR(tp_func_##_name), \
		.iterator = &__traceiter_##_name,			\
		.regfunc = _reg,					\
		.unregfunc = _unreg,					\
		.funcs = NULL };					\
	__TRACEPOINT_ENTRY(_name);					\
	int __traceiter_##_name(void *__data, proto)			\
	{								\
		struct tracepoint_func *it_func_ptr;			\
		void *it_func;						\
									\
		it_func_ptr =						\
			rcu_dereference_raw((&__tracepoint_##_name)->funcs); \
		if (it_func_ptr) {					\
			do {						\
				it_func = READ_ONCE((it_func_ptr)->func); \
				__data = (it_func_ptr)->data;		\
				((void(*)(void *, proto))(it_func))(__data, args); \
			} while ((++it_func_ptr)->func);		\
		}							\
		return 0;						\
	}								\
	DEFINE_STATIC_CALL(tp_func_##_name, __traceiter_##_name);

#define DEFINE_TRACE(name, proto, args)		\
	DEFINE_TRACE_FN(name, NULL, NULL, PARAMS(proto), PARAMS(args));
```

对于 `do_sys_open` 这个 tracepoint，它生成的函数名就是 `trace_do_sys_open`。而这个函数会被内核函数 `do_sys_open()` 调用，从而实现了一个内核的 tracepoint。在这个 tracepoint 函数里，主要的功能是，通过 `__DO_TRACE` 来调用所有注册在这个 tracepoint 上的 probe 函数。而 probe 函数的注册，它可以通过宏定义的 `register_trace_##name` 函数完成。

```c
#define __DO_TRACE_CALL(name, args)					\
	do {								\
		struct tracepoint_func *it_func_ptr;			\
		void *__data;						\
		it_func_ptr =						\
			rcu_dereference_raw((&__tracepoint_##name)->funcs); \
		if (it_func_ptr) {					\
			__data = (it_func_ptr)->data;			\
			static_call(tp_func_##name)(__data, args);	\
		}							\
	} while (0)

#define __DO_TRACE(name, args, cond, rcuidle)				\
	do {								\
		int __maybe_unused __idx = 0;				\
									\
		if (!(cond))						\
			return;						\
									\
		/* srcu can't be used from NMI */			\
		WARN_ON_ONCE(rcuidle && in_nmi());			\
									\
		/* keep srcu and sched-rcu usage consistent */		\
		preempt_disable_notrace();				\
									\
		/*							\
		 * For rcuidle callers, use srcu since sched-rcu	\
		 * doesn't work from the idle path.			\
		 */							\
		if (rcuidle) {						\
			__idx = srcu_read_lock_notrace(&tracepoint_srcu);\
			ct_irq_enter_irqson();				\
		}							\
									\
		__DO_TRACE_CALL(name, TP_ARGS(args));			\
									\
		if (rcuidle) {						\
			ct_irq_exit_irqson();				\
			srcu_read_unlock_notrace(&tracepoint_srcu, __idx);\
		}							\
									\
		preempt_enable_notrace();				\
	} while (0)

#define __DECLARE_TRACE(name, proto, args, cond, data_proto)		\
	extern int __traceiter_##name(data_proto);			\
	DECLARE_STATIC_CALL(tp_func_##name, __traceiter_##name);	\
	extern struct tracepoint __tracepoint_##name;			\
	static inline void trace_##name(proto)				\
	{								\
		if (static_key_false(&__tracepoint_##name.key))		\
			__DO_TRACE(name,				\
				TP_ARGS(args),				\
				TP_CONDITION(cond), 0);			\
		if (IS_ENABLED(CONFIG_LOCKDEP) && (cond)) {		\
			rcu_read_lock_sched_notrace();			\
			rcu_dereference_sched(__tracepoint_##name.funcs);\
			rcu_read_unlock_sched_notrace();		\
		}							\
	}						
...
```

> 可以自己写一个简单 kernel module 来注册一个 probe 函数，把它注册到已有的 treacepoint 上。这样，这个 probe 函数在每次 tracepoint 点被调用到的时候就会被执行。

Kprobe 原理，把目标指令替换，替换的指令可以使程序跑到一个特定的 handler 里，去执行 probe 的函数。

```c

/* file: samples/kprobes/kprobe_example.c
 *
 * a sample kernel module showing the use of kprobes to dump a
 * stack trace and selected registers when kernel_clone() is called.
 *
 * For more information on theory of operation of kprobes, see
 * Documentation/trace/kprobes.rst
 */

#define pr_fmt(fmt) "%s: " fmt, __func__

#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/kprobes.h>

static char symbol[KSYM_NAME_LEN] = "kernel_clone";
module_param_string(symbol, symbol, KSYM_NAME_LEN, 0644);

/* For each probe you need to allocate a kprobe structure */
static struct kprobe kp = {
	.symbol_name	= symbol,
};

/* kprobe pre_handler: called just before the probed instruction is executed */
static int __kprobes handler_pre(struct kprobe *p, struct pt_regs *regs)
{
#ifdef CONFIG_X86
	pr_info("<%s> p->addr = 0x%p, ip = %lx, flags = 0x%lx\n",
		p->symbol_name, p->addr, regs->ip, regs->flags);
#endif
/* define other architectures ARM64, PPC, MIPS, ARM, RISCV, S390*/

	/* A dump_stack() here will give a stack backtrace */
	return 0;
}

/* kprobe post_handler: called after the probed instruction is executed */
static void __kprobes handler_post(struct kprobe *p, struct pt_regs *regs,
				unsigned long flags)
{
#ifdef CONFIG_X86
	pr_info("<%s> p->addr = 0x%p, flags = 0x%lx\n",
		p->symbol_name, p->addr, regs->flags);
#endif
/* define other architectures ARM64, PPC, MIPS, ARM, RISCV, S390*/
}

static int __init kprobe_init(void)
{
	int ret;
	kp.pre_handler = handler_pre;
	kp.post_handler = handler_post;

	ret = register_kprobe(&kp);
	if (ret < 0) {
		pr_err("register_kprobe failed, returned %d\n", ret);
		return ret;
	}
	pr_info("Planted kprobe at %p\n", kp.addr);
	return 0;
}

static void __exit kprobe_exit(void)
{
	unregister_kprobe(&kp);
	pr_info("kprobe at %p unregistered\n", kp.addr);
}

module_init(kprobe_init)
module_exit(kprobe_exit)
MODULE_LICENSE("GPL");
```

在内核中任意一个函数名 / 符号对应的代码地址上注册 probe 函数，分别是 `pre_handler`、 `post_handler` 和 `fault_handler`(会在发生异常的时候调用)。当这个内核函数被执行的时候，已经注册的 probe 函数也会被执行。

Linux tracing 首先利用 tracepoints、kprobes 机制，还有一些别的 events 可以拿到数据；再利用 ftrace、perf、ebpf 等工具收集数据；再后面是使用 bcc、trace-cmd、perf/FlameGraph 等工具友好显示。

## eBPF

eBPF - Extended Berkeley Packet Filter

1992 伯克利实验室的一篇论文 《The BSD Packet Filter: A New Architecture for User-level Packet Capture》描述了 BPF 是如何更加高效灵活地从操作系统内核中抓取网络数据包的。比如 `tcpdump` 工具，它就是利用了 BPF 的技术来抓取 Unix 操作系统节点上的网络包。

BPF 中，B(Buffer)P(Protocol stack)F(Filter), 内核中实现了一个虚拟机，用户态程序通过系统调用，把数据包过滤代码载入到个内核态虚拟机中运行，这样就实现了内核态对数据包的过滤；BPF 模块和网络协议栈代码是相互独立的，BPF 只是通过简单的几个 hook 点，就能从协议栈中抓到数据包，内核网络协议代码变化不影响 BPF 的工作；内核中的 BPF filter 模块使用 buffer 与用户态程序进行通讯，把 filter 的结果返回给用户态程序，这样就不会产生内核态与用户态的上下文切换（context switch）。

eBPF 对 BPF 做了扩展，对虚拟机做了增强，扩展了寄存器和指令集的定义，提高了虚拟机的性能，并且可以处理更加复杂的程序；增加了 eBPF maps，这是一种存储类型，可以保存状态信息，从一个 BPF 事件的处理函数传递给另一个，或者保存一些统计信息，从内核态传递给用户态程序；eBPF 可以处理更多的内核事件，不再只局限在网络事件上。

应用：

- 网络领域，内核态网络包的快速处理和转发，参考 XDP（eXpress Data Path）。

- 安全领域，通过 LSM（Linux Security Module）的 hook 点，eBPF 可以对 Linux 内核做安全监控和访问控制，参考 KRSI（Kernel Runtime Security Instrumentation）文档。

- 内核追踪 / 调试，eBPF 能通过 tracepoints、kprobes、 perf-events 等 hook 点来追踪和调试内核，可以用于在调试生产环境中，解决容器相关问题时使用的方法。

eBPF 编程模型（参考《Kernel analysis using eBPF》）：

一个 eBPF 的程序分为两部分，第一部分是内核态的代码，也就是图中的 `foo_kern.c`，这部分的代码之后会在内核 eBPF 的虚拟机中执行。第二部分是用户态的代码，对应图中的 `foo_user.c`。它的主要功能是负责加载内核态的代码，以及在内核态代码运行后通过 eBPF maps 从内核中读取数据。

内核态的代码需要用 Clang/LLVM 来编译生成 eBPF bytecode。在内核态，eBPF bytecode 会被加载到 eBPF 内核虚拟机中。

`foo_user.c` 编译链接后就会生成一个普通的用户态程序，它会通过 `bpf()` 系统调用做两件事：第一是去加载 eBPF bytecode 文件 `foo_kern.o`，使 `foo_kern.o` 这个 eBPF bytecode 在内核 eBPF 的虚拟机中运行；第二是创建 eBPF maps，用于内核态与用户态的通讯。

执行 BPF 程序之前，BPF Verifier 先要对 eBPF bytecode 进行很严格的指令检查。检查通过之后，再通过 JIT（Just In Time）编译成宿主机上的本地指令。编译成本地指令之后，eBPF 程序就可以在内核中运行了，比如挂载到 tracepoints hook 点，或者用 kprobes 来对内核函数做分析，然后把得到的数据存储到 eBPF maps 中，这样 foo_user 这个用户态程序就可以读到数据了。

eBPF 程序里的三个要素

- eBPF Program Types 定义函数在 eBPF 内核态的类型
  
- eBPF Maps 定义了 key/value 对的存储结构，搭建了 eBPF Program 之间以及用户态和内核态之间的数据交换的桥梁
  
- eBPF Helpers 内核事先定义好的接口函数，方便 eBPF 程序调用这些函数

> 参考资料：Brendan Gregg - BPF Performance Tools；Daniel Thompson - Kernel analysis using eBPF；eBPF 应用例子 - https://github.com/niclashedam/ebpf-kill-example

## BCC

bcc - BPF Compiler Collection

[bcc repo](https://github.com/iovisor/bcc)
